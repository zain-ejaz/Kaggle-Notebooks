{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 10px 100px;\">Solution to Facial Recognition System using a SVM Model</p>","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport shutil\nimport errno\nimport cv2\nimport sklearn\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:30.856418Z","iopub.execute_input":"2023-05-18T21:32:30.857186Z","iopub.status.idle":"2023-05-18T21:32:30.864562Z","shell.execute_reply.started":"2023-05-18T21:32:30.857151Z","shell.execute_reply":"2023-05-18T21:32:30.863416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Copying Dataset","metadata":{}},{"cell_type":"code","source":"# This is a function for copying files or directories from 'src' to 'dest'.\ndef copy(src, dest):\n    try:\n        # shutil.copytree copies an entire directory tree, including all subdirectories.\n        shutil.copytree(src, dest)\n    except OSError as e:\n        # errno.ENOTDIR means the source is a file and not a directory.\n        if e.errno == errno.ENOTDIR:\n            # shutil.copy copies a file from 'src' to 'dest'.\n            shutil.copy(src, dest)\n        else:\n            print('Directory not copied. Error: %s' % e)\n\n# Specify the source and destination paths for the dataset.            \nsrc = '../input/lfwpeople'\ndest = '../LFW/lfw4/lfw_home'\n# Use the copy function to copy the files from source to destination.\ncopy(src,dest)\n# Print the list of files in the source and destination directories.\nprint(os.listdir('../input/lfwpeople'))\nprint(os.listdir('../LFW/lfw4/lfw_home'))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:30.866728Z","iopub.execute_input":"2023-05-18T21:32:30.867598Z","iopub.status.idle":"2023-05-18T21:32:30.888628Z","shell.execute_reply.started":"2023-05-18T21:32:30.867553Z","shell.execute_reply":"2023-05-18T21:32:30.887394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"# Specify the path to the dataset.\npath = '../LFW/lfw4/'\nprint(\"Fetching LFW people dataset from:\", path)\n\n# Fetch the dataset from the specified path and only download the images of people with 80 or more faces.\nlfw_dataset = sklearn.datasets.fetch_lfw_people(data_home = path, min_faces_per_person=80,  download_if_missing = False)\n\nn_samples, h, w = lfw_dataset.images.shape\nprint(\"Fetched dataset with\", n_samples, \"samples\")\n# Set the seed for the numpy random number generator, which is used for creating random splits of the data for training and testing.\nnp.random.seed(42)\n# Assign the image data to 'X'.\nX = lfw_dataset.data\n# Get the number of features in the dataset, which in this case would be the height of the images.\nn_features = X.shape[1]\n\n# Assign the target values to 'y'.\ny = lfw_dataset.target\ntarget_names = lfw_dataset.target_names\n# Get the number of classes in the dataset.\nn_classes = target_names.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:30.890171Z","iopub.execute_input":"2023-05-18T21:32:30.890826Z","iopub.status.idle":"2023-05-18T21:32:31.011058Z","shell.execute_reply.started":"2023-05-18T21:32:30.890790Z","shell.execute_reply":"2023-05-18T21:32:31.009545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"# Print out details regarding the dataset.\nprint(f\"Number of images: {n_samples}\")\nprint(f\"Number of classes: {n_classes}\")\nprint(f\"Image shape: {h} x {w}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:31.013408Z","iopub.execute_input":"2023-05-18T21:32:31.014238Z","iopub.status.idle":"2023-05-18T21:32:31.021991Z","shell.execute_reply.started":"2023-05-18T21:32:31.014183Z","shell.execute_reply":"2023-05-18T21:32:31.020668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new figure to display images with a size of (10, 5).\nplt.figure(figsize=(10, 5))\n# Loop to display the first five images in the dataset.\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(X[i].reshape((h, w)), cmap='gray')\n    plt.title(target_names[y[i]])\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:31.023427Z","iopub.execute_input":"2023-05-18T21:32:31.024160Z","iopub.status.idle":"2023-05-18T21:32:31.490997Z","shell.execute_reply.started":"2023-05-18T21:32:31.024125Z","shell.execute_reply":"2023-05-18T21:32:31.489663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a bar chart to visualise the amount of images for each class.\nlabel, counts = np.unique(y, return_counts=True)\nplt.figure(figsize=(15, 5))\nplt.bar(target_names[label], counts)\nplt.xlabel('Class')\nplt.ylabel('Number of images')\nplt.title('Distribution of classes')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:31.492590Z","iopub.execute_input":"2023-05-18T21:32:31.493588Z","iopub.status.idle":"2023-05-18T21:32:32.028367Z","shell.execute_reply.started":"2023-05-18T21:32:31.493547Z","shell.execute_reply":"2023-05-18T21:32:32.027126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Splitting","metadata":{}},{"cell_type":"code","source":"# Split the dataset into training and testing sets.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:32.030278Z","iopub.execute_input":"2023-05-18T21:32:32.030744Z","iopub.status.idle":"2023-05-18T21:32:32.045243Z","shell.execute_reply.started":"2023-05-18T21:32:32.030702Z","shell.execute_reply":"2023-05-18T21:32:32.043821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying PCA","metadata":{}},{"cell_type":"code","source":"# Set the number of components for further analysis after applying PCA.\nn_components = 200\n# Print the number of components and training examples.\nprint(f\"Extracting the top {n_components} eigenfaces from {X_train.shape[0]} faces\")\n\n# Fit a PCA (Principal Component Analysis) model to the training data.\n# The model will keep the top 200 components based on their significance.\n# PCA is used here to reduce the dimensionality of the data and keep only significant features.\n# svd_solver='randomized' is efficient for large datasets.\n# whiten=True can help the model perform better as it transforms the data to have a mean of 0 and variance of 1.\npca = PCA(n_components=n_components, svd_solver='randomized',whiten=True).fit(X_train)\n\n# Reshapes the components to have the same shape as the images.\neigenfaces = pca.components_.reshape((n_components, h, w))\n\n# Transform the training and testing data by applying the PCA transformation.\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:32.047413Z","iopub.execute_input":"2023-05-18T21:32:32.048323Z","iopub.status.idle":"2023-05-18T21:32:34.000023Z","shell.execute_reply.started":"2023-05-18T21:32:32.048250Z","shell.execute_reply":"2023-05-18T21:32:33.998160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting Model","metadata":{}},{"cell_type":"code","source":"print(\"Fitting the classifier to the training set...\")\n# Create a parameter grid to be used for a grid search. The grid search will find the best parameters for the SVM classifier from the given options.\nparam_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n\n# Initialize an SVM classifier and perform a grid search with cross-validation to find the best parameters.\nclf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n# Fit the classifier to the training data.\nclf = clf.fit(X_train_pca, y_train)\n\n# Get the results of the grid search.\ncv_results = clf.cv_results_\n\n# Print the best parameters found by the grid search.\nprint(\"Best parameters found by grid search:\")\nprint(clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:34.003813Z","iopub.execute_input":"2023-05-18T21:32:34.006378Z","iopub.status.idle":"2023-05-18T21:32:51.304154Z","shell.execute_reply.started":"2023-05-18T21:32:34.006293Z","shell.execute_reply":"2023-05-18T21:32:51.303319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict the labels for the testing data.\ny_pred = clf.predict(X_test_pca)\n\n# Print the classification report for the predictions on the test set.\nprint(\"Predicting people's names on the test set\")\nprint(classification_report(y_test, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:32:51.305451Z","iopub.execute_input":"2023-05-18T21:32:51.305941Z","iopub.status.idle":"2023-05-18T21:32:51.369450Z","shell.execute_reply.started":"2023-05-18T21:32:51.305912Z","shell.execute_reply":"2023-05-18T21:32:51.368244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the confusion matrix for the predictions on the test set.\nprint(confusion_matrix(y_test, y_pred, labels=range(n_classes)))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T21:33:03.154175Z","iopub.execute_input":"2023-05-18T21:33:03.154611Z","iopub.status.idle":"2023-05-18T21:33:03.164108Z","shell.execute_reply.started":"2023-05-18T21:33:03.154576Z","shell.execute_reply":"2023-05-18T21:33:03.162853Z"},"trusted":true},"execution_count":null,"outputs":[]}]}